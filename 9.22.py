import streamlit as st
import streamlit.components.v1 as html
from protlearn.features import (
    paac,
    aac,
    aaindex1,
    entropy,
    atc,
    ctd,
    moran,
    geary,
    qso,
    ngram,
    motif,
    cksaap,
)
import pandas as pd
import numpy as np
import base64
from PIL import Image
from io import BytesIO

# from icecream import ic

# sklean

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import (
    RandomForestClassifier,
    AdaBoostClassifier,
    GradientBoostingClassifier,
)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
import joblib  
 #åŠ è½½æ¨¡å‹ 
def load_rf_model():  
    model_path = "C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\rf_model.pkl"  
    model = joblib.load(model_path)  
    return model
def load_gb_model():  
    model_path = "C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\gb_model.pkl"  
    model = joblib.load(model_path)  
    return model

def _feaprocess(data):#æ•°æ®å¤„ç†
    # test_data, _ = aaindex1(data)
    # test_data_df = pd.DataFrame(test_data)
    test_data_aaindex1, _ = aaindex1(data)
    test_data_ng, _ = ngram(data)
    test_data_ctd, _ = ctd(data)
    test_data_atc, _ = atc(data)
    test_data = np.concatenate(
        (test_data_aaindex1, test_data_ng, test_data_ctd, test_data_atc), axis=1#å››ä¸ªç‰¹å¾å‘é‡æ‹¼æ¥åˆ°ä¸€èµ·
    )
    indices = pd.read_csv("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\train_data\\indices_df.csv", header=None)
    indices = indices.iloc[:, 0]
    indices = np.array(indices)
    indices = indices.tolist()
    test_data = test_data[:, indices]

    train_data = pd.read_csv("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\train_data\\reduced_df.csv", header=None)
    train_data = np.array(train_data)
    train_target = pd.read_csv("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\train_data\\isAMP.csv", header=None)
    train_target = train_target.iloc[:, 0]
    train_target = np.array(train_target)

    return test_data, train_data, train_target

    
# st.set_page_config(page_title="æŠ—èŒè‚½é¢„æµ‹")
st.set_page_config(
    page_title="æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="auto",
    menu_items={
        "About": "# åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹",
    },
)
def add_bg_from_local(image_file):#èƒŒæ™¯
    with open(image_file, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read())
    st.markdown(
    f"""
    <style>
    .stApp {{
        background-image: url(data:image/{"png"};base64,{encoded_string.decode()});
        background-size: cover
    }}
    </style>
    """,
    unsafe_allow_html=True
    )
add_bg_from_local("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\DNA.jpg")
colindex = 0

# st.balloons()
# st.title("æŠ—èŒè‚½ï¼ˆAMPï¼‰é¢„æµ‹")
# st.markdown("### 1.æ•°æ®é¢„å¤„ç†")
centered_text = "<center><h1 >ğŸ§¬ åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹</h1></center>" 
st.markdown(centered_text, unsafe_allow_html=True)
footer_html = """
<style>
    .footer {
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background-color: #f8f9fa;
        color: black;
        text-align: center;
        padding: 10px;
    }
</style>
<div class="footer">
    <p>åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹ &copy;  å­¦æœ¯æœºæ„ï¼šå¾å·åŒ»ç§‘å¤§å­¦</p>
</div>
"""
st.markdown(footer_html, unsafe_allow_html=True)

tab1, tab2, tab3 = st.tabs(["å¼€å§‹é¢„æµ‹", "å…³äºæ¨¡å‹", "è”ç³»æˆ‘ä»¬"])
with tab2:
    st.subheader("ğŸ”¬ å…³äºæ¨¡å‹")
    st.markdown("åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹")
    st.markdown("---")  
    st.subheader("âœ‚ï¸ ç‰¹å¾å¤„ç†æ–¹æ³•")
    st.markdown(
        "æœ¬æ¨¡å‹ä½¿ç”¨**aaindex1ã€ngramã€ctdã€atc**å››ç§ç‰¹å¾è¡¨ç¤ºæ–¹æ³•å°†è›‹ç™½è´¨åºåˆ—å¤„ç†æˆè®¡ç®—æœºå¯è¯†åˆ«çš„å½¢å¼ï¼Œå¹¶æŒ‰ç…§ç‰¹å¾é‡è¦æ€§æ’åºå¹¶é€‰å–å‰50%çš„ç‰¹å¾ä½œä¸ºæœ€ç»ˆç‰¹å¾å‘é‡ï¼Œä»¥åŠ å¿«æ¨¡å‹é¢„æµ‹é€Ÿåº¦"
    )
    st.subheader("")
    st.subheader("ğŸ“ˆ é¢„æµ‹æ¨¡å‹")
    st.markdown(
        "ä½¿ç”¨è€…å¯è‡ªç”±é€‰ç”¨æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½çš„**éšæœºæ£®æ—ç®—æ³•RF**æˆ–**æ¢¯åº¦æå‡ç®—æ³•GBDT**ä½œä¸ºé¢„æµ‹æŠ—èŒè‚½çš„æ¨¡å‹ï¼Œç»è¿‡æˆ‘ä»¬å®éªŒéªŒè¯ï¼Œè¿™ä¸¤ç§ç®—æ³•éƒ½å…·æœ‰è¾ƒé«˜çš„ç²¾åº¦ï¼ˆACCã€F1 scoreã€ROC_AUC)å’Œé©¬ä¿®ç›¸å…³ç³»æ•°(MCC)"
    )
with tab3:
    st.subheader("â˜ï¸ è”ç³»æˆ‘ä»¬")
    st.markdown("å­¦æœ¯æœºæ„:å¾å·åŒ»ç§‘å¤§å­¦")


with tab1:
    col1, col2,= st.columns([1,2])
    with col1:
        st.subheader("ğŸ“¤ ä¸Šä¼ è‚½åºåˆ—æ•°æ®")
        # st.write("- ä¸Šä¼ éœ€è¦æ£€æµ‹çš„è‚½æ•°æ®(**CSV**æ ¼å¼,æ¯è¡Œä¸ºä¸€æ¡è‚½åºåˆ—)")
        test_file = st.file_uploader(
            "ä¸Šä¼ éœ€è¦é¢„æµ‹çš„è‚½æ•°æ®(**CSV**æ ¼å¼,æ¯è¡Œä¸ºä¸€æ¡è‚½åºåˆ—)", type=["csv"]
        )
        if test_file is not None:
            colindex = 1
            testdata = pd.read_csv(test_file, header=0)
            test_data = testdata.iloc[:, 0] 
            test_data = np.array(test_data)
            test_data = test_data.tolist()
            st.write("è‚½åºåˆ—æ•°æ®é¢„è§ˆ,æ–‡ä»¶ä¸­å…±æœ‰" + str(len(test_data)) + "æ¡è‚½åºåˆ—")
            # å±•ç¤ºtestdataç¬¬ä¸€åˆ—çš„æ•°æ®é¢„è§ˆ
            st.write(testdata.iloc[:, 0])
        with col2:
            if colindex == 1:
                st.subheader("ğŸ› ï¸ é€‰æ‹©é¢„æµ‹æ¨¡å‹")
                model = st.radio(
                    label="é€‰æ‹©ä¸€ç§é¢„æµ‹æ¨¡å‹",
                    options=(
                        "éšæœºæ£®æ— RF",
                        "æ¢¯åº¦æå‡ Gradient Boosting Classifier",
                    ),
                    index=0,
                )
                if model == "éšæœºæ£®æ— RF":
                    st.write(
                        "- **æ–¹æ³•è¯´æ˜**ï¼šéšæœºæ£®æ—æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œå®ƒé€šè¿‡æ„å»ºå¤šä¸ªå†³ç­–æ ‘æ¥é¢„æµ‹ç›®æ ‡å˜é‡ã€‚æ¯ä¸ªå†³ç­–æ ‘éƒ½ä½¿ç”¨ä¸åŒçš„ç‰¹å¾å’Œéšæœºé‡‡æ ·ï¼Œç„¶åé€šè¿‡æŠ•ç¥¨æˆ–å¹³å‡æ¥é¢„æµ‹ç›®æ ‡å˜é‡ã€‚"
                    )
                elif model == "æ¢¯åº¦æå‡ Gradient Boosting Classifier":
                    st.write(
                        "- **æ–¹æ³•è¯´æ˜**ï¼šæ¢¯åº¦æå‡åˆ†ç±»å™¨ï¼ˆGradient Boosting Classifierï¼‰æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼ŒåŸºäºæ¢¯åº¦æå‡ï¼ˆGradient Boostingï¼‰æ¡†æ¶ï¼Œä¸»è¦ç”¨äºè§£å†³åˆ†ç±»é—®é¢˜ã€‚"
                    )
                # æŒ‰é’®ï¼Œå¼€å§‹é¢„æµ‹
                if st.button("å¼€å§‹é¢„æµ‹"):
                    # æ˜¾ç¤ºæ—‹è½¬åŠ è½½å™¨
                    with st.spinner("é¢„æµ‹ä¸­..."):
                        test_data_df, train_data, train_target = _feaprocess(test_data)  
                        if model == "éšæœºæ£®æ— RF":  
                            rf_model = load_rf_model()  
                            pred = rf_model.predict_proba(test_data_df)[:, 1]  
                        elif model == "æ¢¯åº¦æå‡ Gradient Boosting Classifier":  
                            gb_model = load_gb_model()  
                            pred = gb_model.predict_proba(test_data_df)[:, 1]  
                             
                        colindex = 2
                        

            if colindex == 2:  
                st.subheader("ğŸ“ƒ é¢„æµ‹ç»“æœ")  
                pred_proba = pd.DataFrame(pred, columns=["æŠ—èŒè‚½æ¦‚ç‡"])  
                result = pd.concat([pd.DataFrame(test_data, columns=["è‚½åºåˆ—"]), pred_proba], axis=1)  
  
                # åº”ç”¨æ ·å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰  
                # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥é€šè¿‡styleæ”¹å˜æ¦‚ç‡çš„é¢œè‰²ï¼Œä½†å¯ä»¥æ ‡è®°é«˜æ¦‚ç‡çš„æ¡ç›®  
                high_prob_threshold = 0.7  # å‡è®¾æˆ‘ä»¬è®¤ä¸ºæ¦‚ç‡å¤§äº0.7ä¸ºé«˜æ¦‚ç‡  
                 
  
                result.style.apply(lambda x: ['background-color: ' + x['é«˜äº®'] for x in x.to_dict().values()], axis=1)  
  
                # æ±‡æ€»ç»Ÿè®¡  
                high_prob_count = (result['æŠ—èŒè‚½æ¦‚ç‡'] > high_prob_threshold).sum()  
                st.write(f"é«˜æ¦‚ç‡ï¼ˆ>{high_prob_threshold}ï¼‰æ˜¯æŠ—èŒè‚½ï¼ˆAMPï¼‰çš„åºåˆ—å…±{high_prob_count}æ¡ã€‚")  
                #st.write(f"é¢„æµ‹ç»“æœå·²æ˜¾ç¤ºï¼Œæ¯è¡Œè‚½åºåˆ—å¯¹åº”çš„'æŠ—èŒè‚½æ¦‚ç‡'åˆ—æ˜¾ç¤ºäº†å…¶æ˜¯æŠ—èŒè‚½çš„æ¦‚ç‡ã€‚")  
                st.write(result)  # è¿™é‡Œæ˜¾ç¤ºçš„æ˜¯å¸¦æœ‰æ ·å¼çš„ DataFrame  
  
                # é‡æ–°é¢„æµ‹æŒ‰é’®  
                if st.button("é‡æ–°é¢„æµ‹"):  
                    st.experimental_rerun()

st.divider() 


