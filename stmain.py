import streamlit as st
import streamlit.components.v1 as html
from protlearn.features import (
    paac,
    aac,
    aaindex1,
    entropy,
    atc,
    ctd,
    moran,
    geary,
    qso,
    ngram,
    motif,
    cksaap,
)
import pandas as pd
import numpy as np

# from icecream import ic

# sklean
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import (
    RandomForestClassifier,
    AdaBoostClassifier,
    GradientBoostingClassifier,
)
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score


def _feaprocess(data):
    # test_data, _ = aaindex1(data)
    # test_data_df = pd.DataFrame(test_data)
    test_data_aaindex1, _ = aaindex1(data)
    test_data_ng, _ = ngram(data)
    test_data_ctd, _ = ctd(data)
    test_data_atc, _ = atc(data)
    test_data = np.concatenate(
        (test_data_aaindex1, test_data_ng, test_data_ctd, test_data_atc), axis=1
    )
    indices = pd.read_csv("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\train_data\\indices_df.csv", header=None)
    indices = indices.iloc[:, 0]
    indices = np.array(indices)
    indices = indices.tolist()
    test_data = test_data[:, indices]

    train_data = pd.read_csv("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\train_data\\reduced_df.csv", header=None)
    train_data = np.array(train_data)
    train_target = pd.read_csv("C:\\Users\\86151\\Desktop\\åŸºäºæœºå™¨å­¦ä¹ çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹\\ä»£ç å’Œæ•°æ®\\train_data\\isAMP.csv", header=None)
    train_target = train_target.iloc[:, 0]
    train_target = np.array(train_target)

    return test_data, train_data, train_target


def _rf(train_data, train_target, test_data):
    rf = RandomForestClassifier(random_state=42)
    rf.fit(train_data, train_target)
    pred = rf.predict(test_data)
    return pred


def _gb(train_data, train_target, test_data):
    gb = GradientBoostingClassifier(random_state=42)
    gb.fit(train_data, train_target)
    pred = gb.predict(test_data)
    return pred


# st.set_page_config(page_title="æŠ—èŒè‚½é¢„æµ‹")
st.set_page_config(
    page_title="æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="auto",
    menu_items={
        "About": "# åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹",
    },
)

colindex = 0

# st.balloons()
# st.title("æŠ—èŒè‚½ï¼ˆAMPï¼‰é¢„æµ‹")
# st.markdown("### 1.æ•°æ®é¢„å¤„ç†")
centered_text = "<center><h1>ğŸ§¬ åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹<h1></center>"
st.markdown(centered_text, unsafe_allow_html=True)
tab1, tab2, tab3 = st.tabs(["å¼€å§‹é¢„æµ‹", "å…³äºæ¨¡å‹", "è”ç³»æˆ‘ä»¬"])

#

#
with tab2:
    st.subheader("ğŸ”¬ å…³äºæ¨¡å‹")
    st.markdown("åŸºäºè®¡ç®—æ–¹æ³•çš„æŠ—èŒè‚½é¢„æµ‹æ¨¡å‹â€”â€”*ä½œè€…ï¼šé¡¾å¿ƒæ„‰*")
    st.subheader("")
    st.subheader("âœ‚ï¸ ç‰¹å¾å¤„ç†æ–¹æ³•")
    st.markdown(
        "æœ¬æ¨¡å‹ä½¿ç”¨**aaindex1ã€ngramã€ctdã€atc**å››ç§ç‰¹å¾è¡¨ç¤ºæ–¹æ³•å°†è›‹ç™½è´¨åºåˆ—å¤„ç†æˆè®¡ç®—æœºå¯è¯†åˆ«çš„å½¢å¼ï¼Œå¹¶æŒ‰ç…§ç‰¹å¾é‡è¦æ€§æ’åºå¹¶é€‰å–å‰50%çš„ç‰¹å¾ä½œä¸ºæœ€ç»ˆç‰¹å¾å‘é‡ï¼Œä»¥åŠ å¿«æ¨¡å‹é¢„æµ‹é€Ÿåº¦"
    )
    st.subheader("")
    st.subheader("ğŸ“ˆ é¢„æµ‹æ¨¡å‹")
    st.markdown(
        "ä½¿ç”¨è€…å¯è‡ªç”±é€‰ç”¨æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½çš„**éšæœºæ£®æ—ç®—æ³•RF**æˆ–**æ¢¯åº¦æå‡ç®—æ³•GBDT**ä½œä¸ºé¢„æµ‹æŠ—èŒè‚½çš„æ¨¡å‹ï¼Œç»è¿‡æˆ‘ä»¬å®éªŒéªŒè¯ï¼Œè¿™ä¸¤ç§ç®—æ³•éƒ½å…·æœ‰è¾ƒé«˜çš„ç²¾åº¦ï¼ˆACCã€F1 scoreã€ROC_AUC)å’Œé©¬ä¿®ç›¸å…³ç³»æ•°(MCC)"
    )
with tab3:
    st.subheader("â˜ï¸ è”ç³»æˆ‘ä»¬")
    st.markdown("å­¦æœ¯æœºæ„:å¾å·åŒ»ç§‘å¤§å­¦")
    st.markdown("ä½œè€…:é¡¾å¿ƒæ„‰")
    st.markdown("ä½œè€…é‚®ç®±:2253608490@qq.com")


with tab1:
    col1, col2, col3 = st.columns(3)
    with col1:
        st.subheader("ğŸ“¤ ä¸Šä¼ è‚½åºåˆ—æ•°æ®")
        # st.write("- ä¸Šä¼ éœ€è¦æ£€æµ‹çš„è‚½æ•°æ®(**CSV**æ ¼å¼,æ¯è¡Œä¸ºä¸€æ¡è‚½åºåˆ—)")
        test_file = st.file_uploader(
            "ä¸Šä¼ éœ€è¦é¢„æµ‹çš„è‚½æ•°æ®(**CSV**æ ¼å¼,æ¯è¡Œä¸ºä¸€æ¡è‚½åºåˆ—)", type=["csv"]
        )
        if test_file is not None:
            colindex = 1
            testdata = pd.read_csv(test_file, header=0)
            test_data = testdata.iloc[:, 0]
            test_data = np.array(test_data)
            test_data = test_data.tolist()
            st.write("è‚½åºåˆ—æ•°æ®é¢„è§ˆ,æ–‡ä»¶ä¸­å…±æœ‰" + str(len(test_data)) + "æ¡è‚½åºåˆ—")
            # å±•ç¤ºtestdataç¬¬ä¸€åˆ—çš„æ•°æ®é¢„è§ˆ
            st.write(testdata.iloc[:, 0])
        with col2:
            if colindex == 1:
                st.subheader("ğŸ› ï¸ é€‰æ‹©é¢„æµ‹æ¨¡å‹")
                model = st.radio(
                    label="é€‰æ‹©ä¸€ç§é¢„æµ‹æ¨¡å‹",
                    options=(
                        "éšæœºæ£®æ— RF",
                        "æ¢¯åº¦æå‡ Gradient Boosting Classifier",
                    ),
                    index=0,
                )
                if model == "éšæœºæ£®æ— RF":
                    st.write(
                        "- **æ–¹æ³•è¯´æ˜**ï¼šéšæœºæ£®æ—æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œå®ƒé€šè¿‡æ„å»ºå¤šä¸ªå†³ç­–æ ‘æ¥é¢„æµ‹ç›®æ ‡å˜é‡ã€‚æ¯ä¸ªå†³ç­–æ ‘éƒ½ä½¿ç”¨ä¸åŒçš„ç‰¹å¾å’Œéšæœºé‡‡æ ·ï¼Œç„¶åé€šè¿‡æŠ•ç¥¨æˆ–å¹³å‡æ¥é¢„æµ‹ç›®æ ‡å˜é‡ã€‚"
                    )
                elif model == "æ¢¯åº¦æå‡ Gradient Boosting Classifier":
                    st.write(
                        "- **æ–¹æ³•è¯´æ˜**ï¼šæ¢¯åº¦æå‡åˆ†ç±»å™¨ï¼ˆGradient Boosting Classifierï¼‰æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼ŒåŸºäºæ¢¯åº¦æå‡ï¼ˆGradient Boostingï¼‰æ¡†æ¶ï¼Œä¸»è¦ç”¨äºè§£å†³åˆ†ç±»é—®é¢˜ã€‚"
                    )
                # æŒ‰é’®ï¼Œå¼€å§‹é¢„æµ‹
                if st.button("å¼€å§‹é¢„æµ‹"):
                    # æ˜¾ç¤ºæ—‹è½¬åŠ è½½å™¨
                    with st.spinner("é¢„æµ‹ä¸­..."):
                        test_data_df, train_data, train_target = _feaprocess(test_data)

                        if model == "éšæœºæ£®æ— RF":
                            pred = _rf(train_data, train_target, test_data_df)
                        elif model == "æ¢¯åº¦æå‡ Gradient Boosting Classifier":
                            pred = _gb(train_data, train_target, test_data_df)
                        colindex = 2
                        #

            with col3:
                if colindex == 2:
                    st.subheader("ğŸ“ƒ é¢„æµ‹ç»“æœ")
                    # restxt = "<center><h3>é¢„æµ‹ç»“æœ<h3></center>"
                    # st.markdown(restxt, unsafe_allow_html=True)

                    # å°†predï¼Œ1ä¸ºæ˜¯ï¼Œ0ä¸ºå¦
                    pred = pd.DataFrame(pred)
                    x = pred.value_counts()[1]
                    y = x / len(pred)
                    pred = pred.replace(0, "å¦")
                    pred = pred.replace(1, "æ˜¯")
                    # æ„å»ºä¸€ä¸ªdataframe,ç¬¬ä¸€åˆ—ä¸ºè‚½åºåˆ—ï¼Œæ•°æ®ä¸ºtest_data,ç¬¬äºŒåˆ—ä¸ºæ˜¯å¦ä¸ºAMPè‚½ï¼Œæ•°æ®ä¸ºpred
                    result = pd.DataFrame(test_data, columns=["è‚½åºåˆ—"])
                    result["æ˜¯å¦ä¸ºAMPè‚½"] = pred
                    # æ˜¯å¦ä¸ºAMPè‚½åˆ—ï¼Œæ˜¯çš„æ•°æ®æ”¹å˜é¢œè‰²
                    result = result.style.map(
                        lambda x: (
                            "background-color: #88DFF2"
                            if x == "æ˜¯"
                            else "background-color: white"
                        )
                    )
                    st.write(
                        f"å¯èƒ½æ˜¯æŠ—èŒè‚½ï¼ˆAMPï¼‰çš„åºåˆ—å…±{x}æ¡ï¼Œå æ¯”{round(y*100,2)}%ã€‚"
                    )
                    st.write(
                        f"å¯èƒ½ä¸æ˜¯è‚½ï¼ˆNonAMPï¼‰çš„åºåˆ—å…±{len(testdata)-x}æ¡ï¼Œå æ¯”{round(100-round(y*100,2),2)}%ã€‚"
                    )
                    st.write(result)
                    # é‡æ–°é¢„æµ‹æŒ‰é’®ï¼Œçº¢è‰²
                    if st.button("é‡æ–°é¢„æµ‹"):
                        st.experimental_rerun()
